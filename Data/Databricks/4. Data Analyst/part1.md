전체적으로 SQL 다루는 법을 가이드함.     
필요한 기능이 있을 때 마다 구글링하는게 좋을 듯.    
<br/>

# 1. Getting Started with Databricks SQL
sql endpoints > create sql endpoint : 클러스터 만드는거랑 유사..    
SQL 다루는 법을 설명해주는데, DBMS 와 비슷..    

<br/><br/>

# 2. Databases, Tables, and Views on Databricks
### 2-1. Databases and table on Databricks
#### The Metastore and the Catalog
- Metastore : stores information metadata necessary to query database entities (Schemas, Locations)    
Persistent to the life of the workspace
- Spark Catalog : Provides the interface to manage the meatastore    
Stores temporary entities    
Each sparksession initializes a sparkcatalog    
A new sparksession is created when notebook is attached to a cluster    
The notebook's SparkSession is deleted when the notebook is detached from a cluster    
- Clusters : 기본적으로 데이터 브릭스를 compute 시키는 power 장치이다. cluster 는 두가지 종류가 있는데     
Interactive clusters : interactive clusters are available to all workspace users with correct permissions    
Job Clusters : job clusters are ephemeral and isolated to a specific job

#### Database and Table
- Databases : databases are logical constructs that organize tables    
Tink of them as creating a "namespace" for a set of tables    
Simplifies discovery and management of data stored in divers locations    
Created against a physical location on an object store    
    Becomes the directory in which managed tables are created      
    Default directory is determined by Spark config : spark.sql.warehouse.dir    
    Default Databricks location is : dbfs/user/hive/warehouse/    
    Use LOCATION to change the default location of managed tables    
Examples    
    Use default loation for managed tables : CREATE DATABASE database1;     
    Use custom location for managed tables : CREATE DATABASE database2 LOCATION < path-to-location >;    
Other options available for CREATE DATABASE in the documentation    
- Tables : Directory of files registered as a relation in a database    
Data location, file type, and schema registered in the metastore    
Underlying files can be of any type : Default = Delta     
Table data persists in the object store    
An active cluster is required to query the metastore and object store
- Managed tables : Default behavior of create/save table operations    
Data is written to a new directory in the database directory
    Data will always be written when creating a non-empty managed table    
    Dafault location : dbfs/user/hive/warehouse/< database_name >.db/< new_table_name >
Data lifecycle managed by the metastore :     
    Drop table operation permanently deletes data    
    Changing relational structure of tables/databases requires physically moving data
- External tables : In Databricks, synonymouse with unmanaged tables    
Created in two ways :     
    Specifying the location to save data when creating a new table : CREATE TABLE table1 Location < path-to-new-location >
    Providing the location of existing data when registering a table
Data lifecycle not tied to metastore operations :    
    Drop table operation removes metadata from metastore, but data is not dropped    
    Can easily clone a table to a new database or table name without moving data   




<br/><br/>
- Summary :    
Metadata for Databases and tables are persisted in the Hive Meatastore    
Using Location in CREATE DATABASE provides a cutom location for managed tables    
Managed tables copy data on CREATE and delete data on DROP    
Unmanaged tables use LOCATION in CREATE    
Unmanaged table data remain in the LOCATION specified even when the table is DROPped

<br/><br/>

#### Views and CTEs on Databricks
- Views : Views register logical queries using the physical plan generated by Catalyst    
Recalculate results each time a view is materialized    
Three different types : Views, Temp Views, Global Temp Views     
Views : persists in the metastore, available across workspace and between sessions    
Tmp views : Does not persist to the metastre, only available in current notebook or job    
Global Temp Views : Does not persist to the metastore, Available to any notebook attached to the cluster, Persists until the cluster is terminated    
- Common Table Expressions ( CTEs ) : Scoped only to the current SQL statement     
- Suggestions for Best Practices : 
Use Delta as the data format when creating tables    
if possible, use external tables    
if not, try to use a location when creating databases    
Locations outside of dbfs provide the most flexibility

<br/><br/>

# 3. How to Ingest Data for Databricks SQL
### 3-1. Importing Data using databricks SQL:
azure storage account 에서 wasbs:// 프로토콜로 데이터를 import 해서 생성한 테이블은 read only 여서 데이터를 수정할 수 없다.   
수정하려면 import 해서 생성한 데이터를 복사하는 것. CREATE table A as SELECT * from table;    
다른 플랫폼을 이용해서 외부 플랫폼에서 생성되는 (가령 유튜브 채널) 데이터도 끌어올 수 있다.    

<br/>

### 3-2. Basic SQL for Databricks SQL
end point 생성하고, 권한주고, azure storage account 에서 데이터 가져오는 방법과 쿼리문 등을 알려줌.    

<br/>

# 4. How to Integrate BI Tools with Databricks SQL
### 4-1. Tableau
Tableau helps people see and understand data with the world's broadest and deepet analytics platform.


### 4-2. Microsoft Power BI
Quickly find meaningful insights within your data and easily build rick, visual analytic reports.

<br/><br/>

# 5. Data visualization on Databricks SQL
