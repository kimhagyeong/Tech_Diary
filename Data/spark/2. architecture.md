## Apache Spark Architecture – Spark Cluster Architecture Explained

spark를 사용하다가 에러를 보게 되면 눈에 익는 단어들이 생긴다. (DAG, Excutor, shuffle 등)    
각 단어들은 spark 를 구성하는 아키텍처 요소들이다. 지금부터 spark 의 architecture 를 잘 설명해준 블로그를 번역하고자 한다.



출처 : https://www.edureka.co/blog/spark-architecture/



Apache spark 는 빅데이터 세계에서 화두가 되고 있는 오픈소스 클러스터 컴퓨팅 프레임워크이다. spark 전문가에 따르면, hadoop 에 비해 100배 정도 메모리가 빠르고 10배정도 디스크가 빠르다고 한다. 이 블로그에서 spark architecture 와 기초에 대해서 간단히 소개하고자 한다.

<br/><br/>

### 이 글에서의 주제
- Spark & its Features
- Spark Architecture Overview
- Spark Eco-System
- Resilient Distributed Datasets (RDDs)
- Working of Spark Architecture
- Example using Scala in Spark Shell


<br/><br/>
## 1. Spark & its Features
스파크와 그 특징    
Apache Spark 는 실시간으로 데이터를 처리하는 오픈소스 클러스터 컴퓨팅 프레임워크이다. Apache spark 의 가장 큰 특징은 어플리케이션의 processing  속도를 높일 수 있는 in-memory cluster computing 를 사용한다는 것이다. (RAM 에 데이터를 저장, 디스크에 저장하는 것보다 내부 최적화 알고리즘이 더 단순하며 더 적은 CPU 명령을 실행하기 때문에 빠르다)    
spark 는 모든 클러스터가 병렬로 처리되고 작업 실패시 재작업을 보장하는 인터페이스를 제공한다. spark 는 batch applications, 반복 algorithms, 대화형 쿼리, streaming과 같은 넓은 작업 범위를 커버하도록 디자인 되어 있다.

<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark2_1.png" width="700"/>

1. speed    
spark 는 대용량 데이터 프로세싱을 하는 Hadoop MapReduce 보다 100배는 빠르다. 파티셔닝을 함으로써 속도를 향상 시킨다.
2. Powerful Caching    
간단한 프로그래밍 계층에서 강력한 캐싱과 디스크 영구 저장을 제공한다. (장치에 전원이 꺼져도 데이터 유지. 비휘발성을 의미. 앞서 RAM을 사용한다고 했으니 보편적인 휘발성 RAM 이 아닌 비휘발성 RAM을 지원한다는 것을 의미)
3. Deployment    
spark는 Mesos, YARN을 사용한 Hadoop, spark 자체 클러스터 메니저를 통해 배포할 수 있습니다.
4. Real-Time    
spark는 in-memory 컴퓨팅을 통해 실시간 컴퓨팅과 적은 지연시간을 제공합니다.
5. Polyglot (여러 언어 가능)    
spark는 높은 레벨의 java, scala, python, R 언어를 지원합니다. 또한 scala, python 에서 shell 도 지원합니다.

<br/><br/>
## 2. Spark Architecture Overview
Apache Spark 는 잘 정의된 아키텍쳐 계층들을 가지고 있는데, 모든 요소들과 계층들은 느슨하게 결합되어 있습니다. 이 아키텍쳐들은 다양한 확장 기능과 라이브러리로 인해 더욱 통합됩니다.




- Resilient Distributed Dataset (RDD) : 탄력적인 분산 데이터 셋
- Directed Acyclic Graph (DAG) : 단방향을 가지는 비순환적인 그래프


<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark2_2.png" width="700"/>

spark 아키텍처에 대해 깊이 들어가기전에, Eco-system이나 RDD 와 같이 spark 의 간단한 기본 컨셉에 대해 설명하고자 한다.

## 2-1. Spark Eco-System
아래 이미지와 같이, spark echosystem는 다양한 구성요소 (spark SQL, Spark Streaming, MLlib, GraphX,Core API component 등) 으로 구성되어 있다.    
<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark2_3.png" width="700"/>



1. Spark Core     
spark core는 대용량 병렬, 분산 데이터 프로세싱의 기본적인 엔진이다. 나아가, core 맨 꼭데기에 설치된 추가적인 라이브러리들은 스트리밍, sql, 머신러닝을 위해 다양한 작업들을 제공해준다. spark core는 메모리 메니지먼트, 결함 복구, 스케쥴링, 분산처리, Job에 있는 클러스터와 상호작용하는 storage 시스템을 모니터링하는 작업들을 제공한다.
2. Spark Streaming    
Spark Streaming은 실시간 스트리밍 데이터를 프로세싱하는데 사용되는 구성요소이다. 또한 이건 core Spark API에서 유용하게 추가해서 사용한다. spark streaming은 실시간 데이터 스트림에서 높은 처리율과 결함 복구를 보장하는 스트림 작업을 가능하게 한다.
3. Spark SQL    
spark SQL은 spark 에 새로운 모듈인데, 관계형 프로세싱과 함수형 프로그래밍 api를 통합하는 것이다. spark SQL은 SQL 쿼리 데이터 뿐만 아니라 Hive Query 언어까지 제공한다. RDBMS에 익숙한 사용자에게 Spark SQL은 전통적인 관계형 데이터 프로세싱과 같은 기존 툴의 범위에서 쉽게 전환할 수 있을 것이다. 
4. GraphX    
graphX 는 spark api를 위한 그래프와 병렬그래프 컴퓨팅이다. 높은 레벨에서 graphX는 spark RDD와 탄력적인 분산 그래프를 확장한 것이다. 탄력적인 분산 그래프(꼭지점과 변들이 방향이 있는 그래프)
5. MLlib(Machine Learning)    
MLlib은 Machine Learning Library의 기준이고 Apache spark 에서 머신러닝으로 사용된다.
6. SparkR
SparkR은 분산 데이터 프레임 실행을 위해 제공되는  R 패키지이다. sparkR은 large 데이터 셋에서 선별, 필터링, 집합 작업을 지원한다.

<br/><br/>
위와 같이, spark 는 R, SQL, Python, Scala, Java를 지원하는 high-level libraries 패키지이다. 이러한 라이브러리는 복잡한 워크플로우에 매끄럽게 통합되도록 변화해왔다. 뿐만 아니라 spark는 다양한 통합 서비스인 MLlib, GraphX, SQL + Data Frames, Streaming services를 수용가능하게 성장해왔다.




그 다음은 spark의 기본적인 데이터 구조인 RDD에 대해 말하고자 한다.

<br/><br/>

## 2-2. Resilient Distributed Dataset (RDD) : 탄력적인 분산 데이터 셋

모든 Spark 애플리케이션을 block로 만들고 이를 RDD라고 부릅니다.    

- Resilient : 결함 회복. 작업에서 실패한 데이터로부터 재시작할 수 있도록 보장.
- Distributed : 클러스터에 여러 노드들에 있는 분산된 데이터
- Dataset : values 를 가지고 있는 파티션된 모음들.
<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark2_4.png" width="700"/>

RDD 는 분산된 collection들을 추상화한 데이터 계층이다. RDD는 변하지 않고 lazy transformations 을 따른다.



이제 어떻게 동작되는지 궁금해질 텐데, RDD안에 데이터들은 key 를 기준으로 chunk 단위로 나눈다. RDD들은 아주 회복력이 높다. (회복력 : 어떤 이슈가 있던 똑같은 data chunk로 여러 각각의 executor nodes로 복제되고 빠르게 회복한다. 또한, 한 executor node가 실패되도 다른 노드들이 여전히 process 된다.)


게다가, 한번 생성된 RDD는 불변하다. 불변하다는 의미는 한번 생성된 객체는 절대 수정이 불가능하다. 그렇지만 transform 은 가능하다.




분산 환경에 대해 말하자면, RDD에 있는 각각의 dataset은 논리적인 파티션으로 분할되어 있는데 이 파티션들은 클러스터의 서로다른 노드에서 작업된다. 그렇기 떄문에, 사용자는 transformations, actions 등을 완전히 병렬로 작업될 수 있다. spark 에서 분산을 관리하니 걱정할 필요 없다.
<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark2_5.png" width="700"/>

RDD를 생성하는 데는 두 가지 방법이 있다. - driver 에서 collection을 병렬화 하는 방법과 외부 storage system에 데이터 셋을 참조하는 방법이다. (외부 storage system : 공유 file system, HDFS, HBase)



RDD를 통해 유저는 두 가지의 작업을 할 수 있다.
1. Transformations : 새로운 RDD를 생성하는 작업
2. Actions : RDD를 작업하고 결과를 driver로 되돌려주는 작업을 하도록 Apache Spark 에게 알려주는 작업.

<br/><br/>


## 3. Working of Spark Architecture

