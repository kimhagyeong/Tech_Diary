
<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark1-1.JPG" width="1000"/>

<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark1-2.JPG" width="1000"/>

<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark1-3.JPG" width="1000"/>

+ RDD 개념이 어렵고 spark 의 시작이라서 가장 먼저 배우게 되면서 내용이 많은데,    
사실 실무에서는 DataFrame -> SQL 로 작업을 많이 하기 때문에 가볍게 넘어가도 좋다.    
<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark1-4.JPG" width="1000"/>

<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark1-5.JPG" width="1000"/>

<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/spark1-6.JPG" width="1000"/>

+ Dataframe 관련해서 : pandas 의 numpy 기반 Dataframe과 유사한 형태의 api를 지원하긴하지만(pandas dataframe 사용자를 끌어들이기 위해..), 최종적으로 SQL을 사용하기 위해 만들어진 것.(따라서 SQL 명령어를 사용해도 dataframe 기반으로 ) Java Object 로 만들어진 RDD 기반. (왜 java 냐면 scala로 만들어져 있기 때문)

스파크에 대해 잘 정리된 블로그 : https://jjaesang.github.io/posts/
