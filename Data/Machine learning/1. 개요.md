## 1. Machine Learning 의 개념

- 기계 학습 또는 머신 러닝은 인공 지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야.
- Y = f(x) 일 때  
  f는 모형(머신 러닝 알고리즘)  
  x 는 입력변수(독립 변수, feature)  
  Y 는 출력변수(종속 변수, 반응 변수)  
- 정확한 f(x) 함수와 그 결과인 Y는 신만이 알 수 있다.  
  우리는 모든 모집단이 아닌 표본을 통해서 근사치를 추정해야 하고 이를 '^' 햇을 씌워서 추정한다는 의미를 표현한다.
<img src="https://github.com/kimhagyeong/Tech_Diary/blob/main/static/%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%80%E1%85%A2%E1%84%8B%E1%85%AD%20%E1%84%92%E1%85%A2%E1%86%BA.png"
     width="700"/>
     
      
## 2. 지도학습과 비지도학습
- 지도 학습  
  Y = f(x)에 대하여 입력 변수(x)와 출력변수(Y)의 관계에 대하여 모델링 하는 것
  회귀(regression) : 입력 변수 x에 대하여 연속형 출력 변수 Y를 예측
  분류(classification) : 입력 변수 x에 대하여 인산형 출력 변수Y (class)를 예측
- 비지도 학습  
  출력 변수 (Y)가 존재하지 않고, 입력 변(X)간의 관계에 대해 모델링 하는 것  
  군집 분석, PCA 등..
- 강화 학습  
  수 많은 시뮬레이션을 통해 현재의 선택이 먼 미래에 보상이 최대가 되도록 학습
  agent 가 action을 취하고 그에 따른 보상을 받고, 보상이 최대가 되도록 하는 최적의 action 방법을 배움.
  
      
## 3. Machine Learning의 종류
- 선형 회귀분석
- 의사결정나무
- KNN(K-Nearest Neighbor)
- Neural Network
- SVM(Support Vector Machine) : Class 간의 거리(margin)가 최대가 되도록 decision boundary를 만드는 방법
- Ensemble Learning
- K-means clustering
      
      
## 4. 모형의 적합성 평가 및 실험 설계
- MSE (mean squared error) : 
  학습 데이터에서의 MSE는 복잡한 모형일수록 감소하지만, 검증 데이터의 MSE는 일정 시점 이후로 증가 (과적합 때문)
- 데이터 분할 방법으로 설계 : 
  과적합 방지를 위해 전체 데이터를 학습 데이터, 검증 데이터, 테스트 데이터(최종 평가로 사용)로 나누어 비율은 보통 5:3:2
- K-Fold 교차 검증 : 
  데이터를 k개 부분으로 나눈 뒤 하나를 검증 집합 나머지를 학습 집합으로 나누고 그 과정을 k번 반복하고 그의 성능 지표를 평균내어 적합성을 평가
- LOOCV(:eave-One-Out Cross Validation) : 
  데이터의 수가 적으로 때 사용하는 교차검증 방법
  총 데이터의 수 n개 만큼 모델을 만드는데, n 번째 데이터만 제외하고 성능 지표를 계산. 이후 n개의 성능 지표를 평균내어 최종 성능 지표 도출
  뭔가 k-fold랑 비슷하나 k-fold는 제외한 데이터를 검증 데이터로 사용하지만 LOOCV는 아예 제외.
    
    
## 5. 과적합 (Overfitting)
- 복잡한 모형일수록, 데이터가 적을수로 과적합이 일어나기 쉬움.
- 분산 : 복잡한 모형일수록 분산이 높음
- 편파성 : 간단한 모형일수록 편파성이 높음
- 분산과 편파성이 작은 모형을 찾아야 함.
